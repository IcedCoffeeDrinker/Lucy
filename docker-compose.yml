services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "5001:5001"
    volumes:
      - ./src:/app/src
    depends_on:
      - whisper
      - csm_tts
    environment:
      - WHISPER_SERVER_URL=http://whisper:8000/v1/
      - CSM_TTS_SERVER_URL=http://csm_tts:8000/v1/
    networks:
      - app-network

  whisper:
    image: fedirz/faster-whisper-server:latest-cuda
    container_name: faster-whisper-server
    ports:
      - "8000:8000"
    volumes:
      - ./models/whisper-data:/root/.cache/huggingface
    environment:
      - OPENAI_API_KEY=cant-be-empty # Placeholder, isn't needed for Lucy
      - OPENAI_BASE_URL=http://localhost:8000/v1/
      - UV_HTTP_MAX_REQUEST_SIZE=52428800 # 50 MB in bytes, increase if you need to upload larger files.
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  csm_tts:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.sesame_csm_openai
      args:
        HF_TOKEN: ${HF_TOKEN}
    container_name: csm-tts-server
    ports:
      - "8001:8000"
    environment:
      HF_TOKEN: ${HF_TOKEN}
      PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"
     # CUDA_VISIBLE_DEVICES: ""  # Force CPU by hiding GPUs
    restart: unless-stopped
    networks:
      - app-network
    # deploy: # Comment out when using CPU
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

networks:
  app-network:
    driver: bridge
